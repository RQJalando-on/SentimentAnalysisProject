---
title: "SentimentAnalysisProject"
author: "Jalando-on, Nandin, Palabrica"
date: "2024-12-14"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyverse)
library(syuzhet)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(lubridate)

tweetsData <- read.csv("tweetsDF.csv")

```

```{r}
tweetsData$text <- iconv(tweetsData$text, from = "UTF-8", to = "ASCII//TRANSLIT", sub = "")
keywordsPattern <- "\\b(blackpink|yg|bornpink|lisa|jennie|rose|jisoo)\\b|:\\(\\(|&amp;|!|:\\(|&lt;/3|:|&lt;|/|~|iphone|android|nody_meow,|rogue_corq,|apobang27095028,|dessouslevide,|junacrawf0rd,|idkaybictdie,|lhcwesq4iebpbzf,|bpbiggestggindw,|lovemyhead,|akinsolaaliu,|nhlandmlb_fan,|virgini47003223,|angelscrown_,|stacebu,|starlight_sasha,|yuna4lifer,|diandianwong,|dillikahoshi,|tomie_jpg,|biyulving,|jshms9|1ov,|run_pjm,|lae__loner,|ariana_n64,|hdragees,|leemandelo,|purpleocean_i,|wildcatalum,|koreankrueger,|straykldswoo,|siang_ping,|lovemyheadwrap,|nyeongive,|cryptocross0ver|reexrco,|clarefl96567112,|wsbt,|killugoners,|maimechantel,|thealexateam,|ttaesthicx,|juliana62208602,|sadfuk99,|the_inspi,|hyckgasm,|hooriapashaa,|seungri_italy,|rawmilklvr,|laurettaland,|amaarzahid,|andiroo_,|__borntoslay_,|gothwolfjk,|3bbbinlove,|globalmyeon,|tianz17,|2korad,|doncastor4,|lesbi,|yolanda71545557,|mochixjm,|nunupaws,|simoncropp,|aoife,|btsvoque,|jeongpark52,|cloudychiwoo,|kaiewitherloavc,|yerimlvs,|mochixjm1,|tear_ofgod,|frothfather,|moatybuns,|richiericil,|maggiemae2019,|ckyunstd,|cyborgslament,|hyukasplush,|cxcileyyyy,|jungwoohehet,|lostinminhyuk,|crazyemio,|cbsaustin,|backtobleuside,|arches_in,|shelleypowers,|christineirishg,|bubblephehe,|minsmitten,|kaysfalling,|verrerenebi,|ntm23,|auroraluvbot,|my_drama_list,|kindordie,|kaede_zen,|luvskeehoo,"
tweetsData$text <- tolower(tweetsData$text)  
tweetsData$text <- gsub("https\\S+", "", tweetsData$text) 
tweetsData$text <- gsub("#", "", gsub("\n", " ", tweetsData$text)) 
tweetsData$text <- gsub("([@?]\\S+)", "", tweetsData$text) 
tweetsData$text <- gsub("\\?", "", tweetsData$text)  
tweetsData$text <- gsub("\\b\\d{2}\\.\\d{2}\\.\\d{4}\\b", "", tweetsData$text)  
tweetsData$text <- gsub(keywordsPattern, "", tweetsData$text, ignore.case = TRUE)  
tweetsData$text <- gsub("<a href=httptwitter.comdownloadandroid rel=nofollow>twitter for android<a>", "", tweetsData$text)
tweetsData$text <- gsub("<a href= rel=nofollow>twitter web app<a>", "", tweetsData$text)
tweetsData$text <- gsub("<a href=httptwitter.comdownloadiphone rel=nofollow>twitter for iphone<a>", "", tweetsData$text)
tweetsData$text <- gsub("<a href=([^>]*?) rel=nofollow>([^<]*?)<a>", "", tweetsData$text)

create_chunks <- function(df, startRow, endRow) {
  return(df[startRow:endRow, ])
}
startRow <- 1
endRow <- 1000
chunkData <- tweetsData[startRow:endRow, ]
chunkData

write.csv(chunkData, "cleaned_tweets.csv", row.names = FALSE)
write.csv(tweetsData, "processed_tweets.csv", row.names = FALSE)
validTexts <- chunkData$text[chunkData$text != ""]
cat("Number of valid texts before preprocessing: ", length(validTexts), "\n")
if (length(validTexts) > 0) {
  
  corpus <- Corpus(VectorSource(validTexts))
  
  corpus <- tm_map(corpus, content_transformer(tolower))
  cat("Number of valid texts after converting to lowercase: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, removePunctuation)
  cat("Number of valid texts after removing punctuation: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, removeNumbers)
  cat("Number of valid texts after removing numbers: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, removeWords, stopwords("en"))
  cat("Number of valid texts after removing stopwords: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, stripWhitespace)
  cat("Number of valid texts after stripping whitespace: ", length(corpus), "\n")
  
  if (length(corpus) > 0) {
    wordcloud(corpus, 
              max.words = 100, 
              random.order = FALSE, 
              colors = brewer.pal(8, "Dark2"), 
              scale = c(3, 0.5))
  } else {
    cat("No valid text left to create a word cloud.\n")
  }
} else {
  cat("No valid texts available to create a word cloud.\n")
}

```

```{r}

tweetsData$Created_At_Round <- as.POSIXct(tweetsData$Created_At_Round, format = "%d/%m/%Y %H:%M", tz = "UTC")
tweetsData$date <- as.Date(tweetsData$Created_At_Round)
tweetsData$hour <- as.numeric(format(tweetsData$Created_At_Round, "%H"))

hourlyTweets <- tweetsData %>%
  group_by(date, hour) %>%
  summarise(tweet_count = n(), .groups = "drop")

plots <- lapply(unique(hourlyTweets$date), function(current_date) {
  date_data <- hourlyTweets %>% filter(date == current_date)
  
  ggplot(date_data, aes(x = hour, y = tweet_count)) +
    geom_line(color = "#A294F9", linewidth = 1) +
    geom_point(color = "#FFF8E6") +
    geom_text(aes(label = tweet_count), vjust = -0.5, color = "#1B1833", size = 3) +
    scale_x_continuous(breaks = 0:23) +
    labs(
      title = paste("Tweet Counts on", format(current_date, "%B, %d, %Y")),
      x = "Hour of the Day",
      y = "Number of Tweets"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      plot.title = element_text(hjust = 0.5)
    )
})

for (i in seq_along(plots)) {
  print(plots[[i]])
}

summaryperDate <- tweetsData %>%
  group_by(date) %>%
  summarise(
    total_tweets = n(),
    unique_hours = n_distinct(hour),
    .groups = "drop"
  )

print(summaryperDate)

```


```{r}
tweetsData$statusSource_clean <- gsub("<.*?>", "", tweetsData$statusSource)
statusCounts <- table(tweetsData$statusSource_clean)
barplot(statusCounts, 
        main = "Tweet Source Distribution", 
        xlab = "Platform", 
        ylab = "Number of Tweets", 
        col = rainbow(length(statusCounts)), 
        las = 2,              
        cex.axis = 0.15)

```

DESCRIBE:

```{r}
library(ggplot2)
library(readr)
library(dplyr)

print(colnames(tweetsData))
```

```{r}
TweetSourceCountsData <- tweetsData %>%
  group_by(tweetSource) %>%
  summarize(Count = n()) %>%
  arrange(desc(Count))
TweetSourceCountsData$tweetSource <- factor(TweetSourceCountsData$tweetSource, 
                                          levels = TweetSourceCountsData$tweetSource)
ggplot(TweetSourceCountsData, aes(x = reorder(tweetSource, -Count), y = Count, fill = tweetSource)) +
  geom_bar(stat = "identity") +
  labs(title = "Tweet Source Comparison",
       x = "Tweet Source",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("iphone" = "#F29F58", "android" = "#441752", "others" = "#9ABF80", "ipad" = "#1F4529", "ifttt" = "#1F509A", "dlvr.it" = "#FA4032"))
```

DESCRIBE: